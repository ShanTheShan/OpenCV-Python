{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73138273",
   "metadata": {},
   "source": [
    "Import libraries for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f77be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ca069",
   "metadata": {},
   "source": [
    "File path in strings, as well as loading the file into cv2.VideoCapture()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5192422",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = 'Traffic_Laramie_1.mp4'\n",
    "filepath2 = 'Traffic_Laramie_2.mp4'\n",
    "\n",
    "video=cv2.VideoCapture('Traffic_Laramie_1.mp4')\n",
    "video2= cv2.VideoCapture('Traffic_Laramie_2.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a6f5d",
   "metadata": {},
   "source": [
    "Data/Information about the two videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9bef40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic_Laramie_1.mp4\n",
      "Video Length:2:57\n",
      "Total frames: 4448.0\n",
      "Fps: 25.0\n",
      "Video Width: 1040\n",
      "Video Height: 600\n",
      "\n",
      "\n",
      "Traffic_Laramie_2.mp4\n",
      "Video Length:1:45\n",
      "Total frames: 2642.0\n",
      "Fps: 25.0\n",
      "Video Width: 1040\n",
      "Video Height: 600\n"
     ]
    }
   ],
   "source": [
    "frames_count, fps, width, height = video.get(cv2.CAP_PROP_FRAME_COUNT), video.get(cv2.CAP_PROP_FPS), video.get(cv2.CAP_PROP_FRAME_WIDTH), video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = int(width)\n",
    "height = int(height)\n",
    "length = frames_count/fps\n",
    "minutes = int(length/60)\n",
    "seconds = int(length%60)\n",
    "duration1 = str(minutes) + ':' + str(seconds)\n",
    "\n",
    "print(filepath1)\n",
    "print(f'Video Length:{duration1}')\n",
    "print(f'Total frames: {frames_count}')\n",
    "print(f'Fps: {fps}')\n",
    "print(f'Video Width: {width}')\n",
    "print(f'Video Height: {height}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "frames_count, fps, width, height = video2.get(cv2.CAP_PROP_FRAME_COUNT), video.get(cv2.CAP_PROP_FPS), video.get(cv2.CAP_PROP_FRAME_WIDTH), video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = int(width)\n",
    "height = int(height)\n",
    "length = frames_count/fps\n",
    "minutes = int(length/60)\n",
    "seconds = int(length%60)\n",
    "duration2 = str(minutes) + ':' + str(seconds)\n",
    "\n",
    "print(filepath2)\n",
    "print(f'Video Length:{duration2}')\n",
    "print(f'Total frames: {frames_count}')\n",
    "print(f'Fps: {fps}')\n",
    "print(f'Video Width: {width}')\n",
    "print(f'Video Height: {height}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b36777",
   "metadata": {},
   "source": [
    "### The Tracking Algorithm\n",
    "\n",
    "Below is the class that will be utilized to track and count the number of cars that go from the city's downtown to the city centre. It is based off two mathematical principles, Euclidean Distance and Centroid.\n",
    "\n",
    "- Euclidean distance is the distance between two points[1].\n",
    "\n",
    "- The centroid is the centre of an object or figure[2].\n",
    "\n",
    "The class has three methods that will be called. The first method is `update_frame()`. \n",
    "\n",
    "The methodology behind tracking the cars is this. Firstly, we need to calculate the rectangle based off the countour area detected in the foreground of the video, using background subtraction, as seen in Task/Exercise (1.1), and in here as well. We store all the rectangles in a list of lists and pass it into `update_frame()`. Here, the function will calculate the centroid of the rectangle, which is the car. The centroids are then stored in a separate list, `centroid_history`.\n",
    "\n",
    "In other words, for every frame in the video, we pass in the rectangle, which is the car, and calculate its centroid.\n",
    "\n",
    "The next method we call is `track()`. Using the history of detected cars and their centroids,`centroid history`, we calculate euclidean distance between the position of the centroids in the current frame, and the previous frame. This is frame difference technique at work. If the distance is below the threshold, we are tracking the same car, if it is above, it is a new car, and we can update the car counter.  \n",
    "\n",
    "Lastly, we call `cars_counted()` to get the number of cars counted that are heading towards the city centre, in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fdc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tracking_algorithm():\n",
    "    def __init__(self):\n",
    "        #to store all centroid history in current frames and previous frame\n",
    "        self.centroid_history = []\n",
    "        self.car_ID_Counter = 0\n",
    "        \n",
    "    def get_centroid(self,x, y, w, h):\n",
    "        cx = x + int(w/2)\n",
    "        cy = y + int(h/2)\n",
    "        return cx,cy\n",
    "\n",
    "    def euclidean_distance(self,x1,x2):\n",
    "        distance = np.sqrt(np.sum((x1-x2)**2))\n",
    "        return distance\n",
    "    \n",
    "    def update_frame(self,rects):       \n",
    "        #we want to store the centroids as a list of lists\n",
    "        singular_object = []\n",
    "        \n",
    "        for rect in rects:\n",
    "            #rects in a list of [x,y,w,h]'s\n",
    "            x,y,width,height = rect\n",
    "            \n",
    "            centroid = self.get_centroid(x,y,width,height)\n",
    "            singular_object.append(centroid)\n",
    "        \n",
    "        self.centroid_history.append(singular_object)\n",
    "        \n",
    "        #we only want to have the current frame and previous frame's centroid\n",
    "        #so if we have length 3, we delete the first elem in the list\n",
    "        #essentially leaving us with the previous frame[0], and the current frame[1]\n",
    "        if len(self.centroid_history) == 3:\n",
    "            self.centroid_history.pop(0)\n",
    "        \n",
    "    def track(self):\n",
    "        #calculate euclidean of current centroid against previous\n",
    "        if len(self.centroid_history) == 2:    \n",
    "            curr = self.centroid_history[-1]\n",
    "            prev = self.centroid_history[0]\n",
    "\n",
    "            #our list of tuples is store [(x,y)], we access x only\n",
    "            curr = curr[0][0]\n",
    "            prev = prev[0][0]\n",
    "            eucd = self.euclidean_distance(curr,prev)\n",
    "            \n",
    "            #we are tracking the same car\n",
    "            if eucd < 50:\n",
    "                pass\n",
    "            #we have found a new car\n",
    "            else:\n",
    "                self.car_ID_Counter += 1\n",
    "    \n",
    "    #returns counted cars real time\n",
    "    def cars_counted(self):\n",
    "        return self.car_ID_Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faed160",
   "metadata": {},
   "source": [
    "### Main\n",
    "\n",
    "Here is the main script, similar to Task/Exercise 1.1. Utilizing background subtraction, as well as additional smoothing[3] and morphological transformations[4], which were derived from the OpenCV documentation, which can be viewed here [smoothing techniques](https://docs.opencv.org/3.4/d4/d13/tutorial_py_filtering.html), and here [transformations](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html).\n",
    "\n",
    "This is was done to solidify the background subtraction between the cars and Main Street, providing more stable and reliable centroid coordinates, when rectangle of the car's countours is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd22b91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#read until video is completed or we press 'Q'\n",
    "def analyze_video(video,video_string):\n",
    "    '''pass the cv2 video object and directory of the video file'''\n",
    "    assert isinstance(video_string,str), 'arguement passed in was not a string'\n",
    "    \n",
    "    if (video.isOpened()== False): \n",
    "        print(\"Error opening video file\")\n",
    "    \n",
    "    if video_string == 'Traffic_Laramie_1.mp4':\n",
    "        print('File Name and Duration:')\n",
    "        print(video_string,duration1)\n",
    "    else:\n",
    "        print('File Name and Duration:')\n",
    "        print(video_string,duration2)\n",
    "    \n",
    "    #detect objects that are being captured\n",
    "    detect_objs = cv2.createBackgroundSubtractorMOG2(varThreshold=20,detectShadows=False)\n",
    "    \n",
    "    #our tracking algorithm\n",
    "    car_tracker = tracking_algorithm()\n",
    "\n",
    "    #list to store the number of detected cars\n",
    "    detected_cars = []\n",
    "    \n",
    "    save_prev_frame=0\n",
    "    \n",
    "    while True:    \n",
    "        #capture frame-by-frame\n",
    "        check, frame = video.read()\n",
    "        current_frame = video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        #if we reach the end of the video, check will be false\n",
    "        if not check:\n",
    "                break\n",
    "        \n",
    "        car_counter = car_tracker.cars_counted()\n",
    "        \n",
    "        #every new frame, we have an empty list of detected cars, as we do not want to store old frame's car\n",
    "        detected_cars.clear()\n",
    "        \n",
    "        #define 'main street''s dimension\n",
    "        main_street = frame[300:420,100:820]\n",
    "\n",
    "        #apply gray and blur to region of interest, main_street\n",
    "        gray = cv2.cvtColor(main_street,cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0 )\n",
    "\n",
    "        foreground_mask  = detect_objs.apply(blur)\n",
    "\n",
    "        #to apply additional transformation to frame\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  \n",
    "        closing = cv2.morphologyEx(foreground_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)\n",
    "        dilation = cv2.dilate(opening,kernel,iterations=2)\n",
    "\n",
    "        #get contours from the foreground_mask\n",
    "        contours,*extra = cv2.findContours(foreground_mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #rgb colors values\n",
    "        green = (0,255,0)\n",
    "        red = (0,0,255)\n",
    "        \n",
    "        #draw box to highlight cars and display car counter\n",
    "        car_counter_display = cv2.putText(frame,'Cars To City Centre:',(10,60),cv2.FONT_HERSHEY_SIMPLEX,1,red,2)\n",
    "        car_counter_increment = cv2.putText(frame,str(car_counter),(350,60),cv2.FONT_HERSHEY_SIMPLEX,1,red,2)\n",
    "        \n",
    "        #draw box and text to label main street\n",
    "        main_street_start = (0,270)\n",
    "        main_street_end = (1039,599)\n",
    "        cv2.rectangle(frame,main_street_start,main_street_end,red,2)\n",
    "        cv2.putText(frame,'Main Street',(10,260),cv2.FONT_HERSHEY_SIMPLEX,1,red,2)\n",
    "        \n",
    "        for cont in contours:\n",
    "            contour_area = cv2.contourArea(cont)\n",
    "            if(contour_area>3000):\n",
    "                #get the cars, push the cords as a list, into detected_cars\n",
    "                x,y,width,height = cv2.boundingRect(cont)\n",
    "                geometry = [x,y,width,height]\n",
    "                detected_cars.append(geometry)\n",
    "                \n",
    "                #call function to calculate detected cars\n",
    "                car_tracker.update_frame(detected_cars)\n",
    "                car_tracker.track()\n",
    "                \n",
    "                #drawing of green box to highlight cars\n",
    "                cv2.rectangle(main_street,(x,y),(x+width,y+height),green,2)           \n",
    "\n",
    "               \n",
    "        td = timedelta(seconds=(current_frame / fps))\n",
    "        minutes = td.total_seconds() / 60\n",
    "        \n",
    "        if minutes == 1.00:\n",
    "            car_1_min = car_counter\n",
    "            print('Cars in 1st minute: ',car_counter)\n",
    "            \n",
    "        if minutes == 2.00:           \n",
    "            print('Cars in 2nd minute: ',car_counter-car_1_min)\n",
    "        \n",
    "        if check == True:\n",
    "            cv2.imshow(\"Main_street_1.2\",frame)\n",
    "            #cv2.imshow(\"Frame Differencing\",dilation)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            if key == ord('p'):\n",
    "                cv2.waitKey(-1) #wait until any key is pressed\n",
    "                \n",
    "    #after the loop release the video object\n",
    "    video.release()\n",
    "    #destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f'Total number of cars: {car_counter}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c655b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name and Duration:\n",
      "Traffic_Laramie_1.mp4 2:57\n",
      "Cars in 1st minute:  2\n",
      "Cars in 2nd minute:  2\n",
      "Total number of cars: 6\n",
      "\n",
      "File Name and Duration:\n",
      "Traffic_Laramie_2.mp4 1:45\n",
      "Cars in 1st minute:  2\n",
      "Total number of cars: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_video(video,filepath1)\n",
    "analyze_video(video2,filepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4671a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Cuemath. (n.d.). Euclidean Distance Formula - Derivation, Examples. [online] Available at: https://www.cuemath.com/euclidean-distance-formula/.\n",
    "\n",
    "[2] www.engineeringtoolbox.com. (n.d.). Centroids of Plane Areas. [online] Available at: https://www.engineeringtoolbox.com/centroids-areas-d_2174.html.\n",
    "\n",
    "[3] docs.opencv.org. (n.d.). OpenCV: Smoothing Images. [online] Available at: https://docs.opencv.org/3.4/d4/d13/tutorial_py_filtering.html.\n",
    "\n",
    "[4] docs.opencv.org. (n.d.). OpenCV: Morphological Transformations. [online] Available at: https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
